{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a22be6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, fitz, faiss, PyPDF2, tiktoken, pdfplumber, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5a90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ad127",
   "metadata": {},
   "source": [
    "### 삼성증권 리포트 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "498f5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: samsungpop\\2025091217070763K_02_01.pdf\n",
      "Downloaded: samsungpop\\2025091216121269K_02_03.pdf\n",
      "Downloaded: samsungpop\\2025091209474022K_02_05.pdf\n",
      "Downloaded: samsungpop\\2025091209083373K_02_03.pdf\n",
      "Downloaded: samsungpop\\2025091210282804K_02_11.pdf\n",
      "Downloaded: samsungpop\\2025091212435266K_02_03.pdf\n",
      "Already exists, skipped: samsungpop\\2025091207551323K_02_02.pdf\n"
     ]
    }
   ],
   "source": [
    "# 1. 요청\n",
    "url = \"https://www.samsungpop.com/sscommon/jsp/search/research/research_pop.jsp\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (compatible; ResearchBot/1.0)\"}\n",
    "resp = requests.post(url, headers=headers, timeout=10)\n",
    "\n",
    "if resp.status_code != 200:\n",
    "    raise Exception(f\"Request failed: {resp.status_code}\")\n",
    "\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "# 2. fileName 추출\n",
    "file_names = []\n",
    "table = soup.find(\"table\", class_=\"tbl-type board\")\n",
    "for a_tag in table.find_all(\"a\", href=True, title=True):\n",
    "    href = a_tag['href']\n",
    "    if \"fileName=\" in href:\n",
    "        file_name = href.split(\"fileName=\")[-1]\n",
    "        file_names.append(file_name)\n",
    "\n",
    "# 3. PDF 다운로드\n",
    "os.makedirs(\"samsungpop\", exist_ok=True)\n",
    "base_url = \"http://www.samsungpop.com/common.do?cmd=down&saveKey=research.pdf&\"\n",
    "\n",
    "for file_name in file_names:\n",
    "    pdf_url = base_url + \"fileName=\" + file_name\n",
    "    filename = file_name.split(\"/\")[-1]  # 파일명만 추출\n",
    "    filepath = os.path.join(\"samsungpop\", filename)\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Already exists, skipped: {filepath}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        r = requests.get(pdf_url, headers=headers, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"Downloaded: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d518ae53",
   "metadata": {},
   "source": [
    "### pdf 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e53349d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"samsungpop\"\n",
    "output_dir = \"processed_pdf\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1daeab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2025091207551323K_02_02.pdf ...\n"
     ]
    }
   ],
   "source": [
    "def extract_lines(word_list, line_tol=3):\n",
    "    \"\"\"단어 리스트를 top 좌표 기준으로 줄 단위로 정렬\"\"\"\n",
    "    word_list = sorted(word_list, key=lambda w: (float(w['top']), float(w['x0'])))\n",
    "    lines = []\n",
    "    buffer = []\n",
    "    last_top = None\n",
    "    for w in word_list:\n",
    "        top = float(w['top'])\n",
    "        if last_top is not None and abs(top - last_top) > line_tol:\n",
    "            if buffer:\n",
    "                lines.append(\" \".join(buffer))\n",
    "            buffer = [w['text']]\n",
    "        else:\n",
    "            buffer.append(w['text'])\n",
    "        last_top = top\n",
    "    if buffer:\n",
    "        lines.append(\" \".join(buffer))\n",
    "    return lines\n",
    "\n",
    "def process_text(lines):\n",
    "    \"\"\"줄 단위 텍스트를 문장 단위로 재조합하고 숫자/표/불릿 처리\"\"\"\n",
    "    paragraphs = []\n",
    "    buffer = \"\"\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if re.match(r\"^[\\d\\.\\%\\(\\)\\- ]+$\", line) or re.match(r\"^(\\•|\\d+\\.)\\s*\", line):\n",
    "            if buffer:\n",
    "                paragraphs.append(buffer.strip())\n",
    "                buffer = \"\"\n",
    "            paragraphs.append(line)\n",
    "        else:\n",
    "            buffer = f\"{buffer} {line}\" if buffer else line\n",
    "            sentences = re.split(r'(?<=[.!?;:])\\s+', buffer)\n",
    "            if len(sentences) > 1:\n",
    "                paragraphs.extend([s.strip() for s in sentences[:-1] if s.strip()])\n",
    "                buffer = sentences[-1]\n",
    "    if buffer:\n",
    "        paragraphs.append(buffer.strip())\n",
    "    return \"\\n\".join(paragraphs)\n",
    "\n",
    "def process_pdf(pdf_file, output_dir):\n",
    "    \"\"\"PDF 파일을 열어 페이지별 좌/우 열 텍스트를 처리하고 저장\"\"\"\n",
    "    pdf_name = pdf_file.name\n",
    "    print(f\"Processing {pdf_name} ...\")\n",
    "\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages[:-1], start=1):  # 마지막 페이지 제외\n",
    "            words = page.extract_words(x_tolerance=3, y_tolerance=3, keep_blank_chars=False)\n",
    "            if not words:\n",
    "                continue\n",
    "\n",
    "            # 좌/우 열 경계 추정\n",
    "            x_coords = np.array([float(w['x0']) for w in words])\n",
    "            hist, bin_edges = np.histogram(x_coords, bins=50)\n",
    "            split_index = np.argmax(hist[1:]) + 1\n",
    "            split_x = (bin_edges[split_index] + bin_edges[split_index-1]) / 2\n",
    "\n",
    "            left_lines = extract_lines([w for w in words if float(w['x0']) <= split_x])\n",
    "            right_lines = extract_lines([w for w in words if float(w['x0']) > split_x])\n",
    "\n",
    "            left_final = process_text(left_lines)\n",
    "            right_final = process_text(right_lines)\n",
    "\n",
    "            # 파일 저장\n",
    "            left_file = os.path.join(output_dir, f\"{pdf_name}_page{page_num}_left_final.txt\")\n",
    "            with open(left_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(left_final)\n",
    "\n",
    "            right_file = os.path.join(output_dir, f\"{pdf_name}_page{page_num}_right_final.txt\")\n",
    "            with open(right_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(right_final)\n",
    "\n",
    "\n",
    "for pdf_file in Path(pdf_dir).glob(\"*.pdf\"):\n",
    "    process_pdf(pdf_file, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fafd3744448ea7b7a7f771c152258982b6db271f1b37b6fc49a7eabbcc1dc05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
